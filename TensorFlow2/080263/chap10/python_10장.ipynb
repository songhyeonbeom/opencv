{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.1 희소표현(Sparse Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "class2=pd.read_csv(\"../chap10/data/class2.csv\")\n",
    "\n",
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "train_x = label_encoder.fit_transform(class2['class2'])\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.2 횟수기반 임베딩\n",
    "#Counter Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 13,\n",
       " 'is': 7,\n",
       " 'last': 8,\n",
       " 'chance': 2,\n",
       " 'and': 0,\n",
       " 'if': 6,\n",
       " 'you': 15,\n",
       " 'do': 3,\n",
       " 'not': 10,\n",
       " 'have': 5,\n",
       " 'will': 14,\n",
       " 'never': 9,\n",
       " 'get': 4,\n",
       " 'any': 1,\n",
       " 'one': 11,\n",
       " 'please': 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is last chance.',\n",
    "    'and if you do not have this chance.',\n",
    "    'you will never get any chance.',\n",
    "    'will you do get this one?',\n",
    "    'please, get this chance',\n",
    "]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(['you will never get any chance.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last': 6,\n",
       " 'chance': 1,\n",
       " 'if': 5,\n",
       " 'you': 11,\n",
       " 'do': 2,\n",
       " 'not': 8,\n",
       " 'have': 4,\n",
       " 'will': 10,\n",
       " 'never': 7,\n",
       " 'get': 3,\n",
       " 'any': 0,\n",
       " 'one': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=[\"and\", \"is\", \"please\", \"this\"]).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도를 위한 3 x 3 행렬을 만들었습니다.\n",
      "[[1.       0.224325 0.      ]\n",
      " [0.224325 1.       0.      ]\n",
      " [0.       0.       1.      ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
    "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
    "print ('유사도를 위한', str(doc_distance.get_shape()[0]), 'x', str(doc_distance.get_shape()[1]), '행렬을 만들었습니다.')\n",
    "print(doc_distance.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.3 예측기반 임베딩\n",
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['once',\n",
       "  'upon',\n",
       "  'a',\n",
       "  'time',\n",
       "  'in',\n",
       "  'london',\n",
       "  ',',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'went',\n",
       "  'out',\n",
       "  'to',\n",
       "  'a',\n",
       "  'dinner',\n",
       "  'party',\n",
       "  'leaving',\n",
       "  'their',\n",
       "  'three',\n",
       "  'children',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'at',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'wendy',\n",
       "  'had',\n",
       "  'tucked',\n",
       "  'her',\n",
       "  'younger',\n",
       "  'brothers',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'to',\n",
       "  'bed',\n",
       "  ',',\n",
       "  'she',\n",
       "  'went',\n",
       "  'to',\n",
       "  'read',\n",
       "  'a',\n",
       "  'book',\n",
       "  '.'],\n",
       " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
       " ['he', 'was', 'flying', '.'],\n",
       " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
       " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
       " ['“', 'hello', '!'],\n",
       " ['who', 'are', 'you', '?'],\n",
       " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
       " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
       " ['my',\n",
       "  'shadow',\n",
       "  'wouldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'me.',\n",
       "  '”',\n",
       "  ',',\n",
       "  'he',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
       " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
       " ['wendy',\n",
       "  'took',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'and',\n",
       "  'sewed',\n",
       "  'it',\n",
       "  'to',\n",
       "  'his',\n",
       "  'shoe',\n",
       "  'tips',\n",
       "  '.'],\n",
       " ['now',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'followed',\n",
       "  'him',\n",
       "  'wherever',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'went',\n",
       "  '!'],\n",
       " ['he',\n",
       "  'was',\n",
       "  'delighted',\n",
       "  'and',\n",
       "  'asked',\n",
       "  'wendy',\n",
       "  '“',\n",
       "  'why',\n",
       "  'don',\n",
       "  '’',\n",
       "  't',\n",
       "  'you',\n",
       "  'come',\n",
       "  'with',\n",
       "  'me',\n",
       "  'to',\n",
       "  'my',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['the', 'neverland', '.'],\n",
       " ['i',\n",
       "  'lived',\n",
       "  'there',\n",
       "  'with',\n",
       "  'my',\n",
       "  'fairy',\n",
       "  'tinker',\n",
       "  'bell.',\n",
       "  '”',\n",
       "  'wendy',\n",
       "  '?'],\n",
       " ['“', 'oh', '!'],\n",
       " ['what', 'a', 'wonderful', 'idea', '!'],\n",
       " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
       " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['of', 'course', '!'],\n",
       " ['get',\n",
       "  'them',\n",
       "  'we',\n",
       "  'will',\n",
       "  'all',\n",
       "  'fly',\n",
       "  'together.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'replied',\n",
       "  'and',\n",
       "  'so',\n",
       "  'it',\n",
       "  'was',\n",
       "  '.'],\n",
       " ['five',\n",
       "  'little',\n",
       "  'figures',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'of',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'and',\n",
       "  'headed',\n",
       "  'towards',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'they',\n",
       "  'flew',\n",
       "  'over',\n",
       "  'the',\n",
       "  'island',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'told',\n",
       "  'the',\n",
       "  'children',\n",
       "  'more',\n",
       "  'about',\n",
       "  'his',\n",
       "  'homeland',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'who',\n",
       "  'get',\n",
       "  'lost',\n",
       "  'come',\n",
       "  'and',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'and',\n",
       "  'me',\n",
       "  ',',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
       " ['the',\n",
       "  'mermaids',\n",
       "  'live',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lagoon',\n",
       "  'around',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['and',\n",
       "  'a',\n",
       "  'very',\n",
       "  'mean',\n",
       "  'pirate',\n",
       "  'called',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'keeps',\n",
       "  'troubling',\n",
       "  'everyone',\n",
       "  '.'],\n",
       " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
       " ['so',\n",
       "  'the',\n",
       "  'captain',\n",
       "  'had',\n",
       "  'to',\n",
       "  'put',\n",
       "  'a',\n",
       "  'hook',\n",
       "  'in',\n",
       "  'its',\n",
       "  'place',\n",
       "  '.'],\n",
       " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
       " ['and', 'rightly', 'so', '!'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'ever',\n",
       "  'found',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'it',\n",
       "  'will',\n",
       "  'eat',\n",
       "  'up',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'it',\n",
       "  'couldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'eat',\n",
       "  'last',\n",
       "  'time.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
       " ['and',\n",
       "  'to',\n",
       "  'the',\n",
       "  'surprise',\n",
       "  'of',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'let',\n",
       "  'them',\n",
       "  'in',\n",
       "  'through',\n",
       "  'a',\n",
       "  'small',\n",
       "  'opening',\n",
       "  'in',\n",
       "  'a',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['inside',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'was',\n",
       "  'a',\n",
       "  'large',\n",
       "  'room',\n",
       "  'with',\n",
       "  'children',\n",
       "  'inside',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['somewhere',\n",
       "  'huddled',\n",
       "  'by',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'in',\n",
       "  'the',\n",
       "  'corner',\n",
       "  'and',\n",
       "  'somewhere',\n",
       "  'playing',\n",
       "  'amongst',\n",
       "  'themselves',\n",
       "  '.'],\n",
       " ['their',\n",
       "  'faces',\n",
       "  'lit',\n",
       "  'up',\n",
       "  'when',\n",
       "  'they',\n",
       "  'saw',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  ',',\n",
       "  'and',\n",
       "  'their',\n",
       "  'guests',\n",
       "  '.'],\n",
       " ['“', 'hello', 'everyone', '.'],\n",
       " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['they',\n",
       "  'will',\n",
       "  'be',\n",
       "  'staying',\n",
       "  'with',\n",
       "  'us',\n",
       "  'from',\n",
       "  'now',\n",
       "  'on.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'introduced',\n",
       "  'them',\n",
       "  'to',\n",
       "  'all',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['a', 'few', 'days', 'passed', '.'],\n",
       " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
       " ['wendy',\n",
       "  'would',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'in',\n",
       "  'the',\n",
       "  'day',\n",
       "  'and',\n",
       "  'would',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brothers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'evening',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'would',\n",
       "  'cook',\n",
       "  'for',\n",
       "  'them',\n",
       "  'and',\n",
       "  'stitch',\n",
       "  'new',\n",
       "  'clothes',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'even',\n",
       "  'made',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'new',\n",
       "  'dress',\n",
       "  'for',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  '.'],\n",
       " ['one',\n",
       "  'evening',\n",
       "  ',',\n",
       "  'as',\n",
       "  'they',\n",
       "  'were',\n",
       "  'out',\n",
       "  'exploring',\n",
       "  'the',\n",
       "  'island',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'warned',\n",
       "  'everyone',\n",
       "  'and',\n",
       "  'said',\n",
       "  ',',\n",
       "  '“',\n",
       "  'hide',\n",
       "  '!'],\n",
       " ['hide', '!'],\n",
       " ['pirates', '!'],\n",
       " ['and',\n",
       "  'they',\n",
       "  'have',\n",
       "  'kidnapped',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'princess',\n",
       "  'tiger',\n",
       "  'lily',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'have',\n",
       "  'kept',\n",
       "  'her',\n",
       "  'there',\n",
       "  ',',\n",
       "  'tied',\n",
       "  'up',\n",
       "  'by',\n",
       "  'the',\n",
       "  'rocks',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'was',\n",
       "  'afraid',\n",
       "  'and',\n",
       "  'the',\n",
       "  'princess',\n",
       "  'would',\n",
       "  'drown',\n",
       "  ',',\n",
       "  'is',\n",
       "  'she',\n",
       "  'fell',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  '.'],\n",
       " ['so',\n",
       "  ',',\n",
       "  'in',\n",
       "  'a',\n",
       "  'voice',\n",
       "  'that',\n",
       "  'sounded',\n",
       "  'like',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  ',',\n",
       "  'he',\n",
       "  'shouted',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'guarded',\n",
       "  'her',\n",
       "  ',',\n",
       "  '“',\n",
       "  'you',\n",
       "  'fools',\n",
       "  '!'],\n",
       " ['let', 'her', 'go', 'at', 'once', '!'],\n",
       " ['do',\n",
       "  'it',\n",
       "  'before',\n",
       "  'i',\n",
       "  'come',\n",
       "  'there',\n",
       "  'or',\n",
       "  'else',\n",
       "  'i',\n",
       "  'will',\n",
       "  'throw',\n",
       "  'each',\n",
       "  'one',\n",
       "  'of',\n",
       "  'you',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'got',\n",
       "  'scared',\n",
       "  'and',\n",
       "  'immediately',\n",
       "  'released',\n",
       "  'the',\n",
       "  'princes',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'quickly',\n",
       "  'dived',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  'and',\n",
       "  'swam',\n",
       "  'to',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'her',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['soon',\n",
       "  'everyone',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'had',\n",
       "  'rescued',\n",
       "  'the',\n",
       "  'princess',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'had',\n",
       "  'tricked',\n",
       "  'his',\n",
       "  'men',\n",
       "  'he',\n",
       "  'was',\n",
       "  'furious',\n",
       "  '.'],\n",
       " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
       " ['that',\n",
       "  'night',\n",
       "  'wendy',\n",
       "  'told',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'that',\n",
       "  'she',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brother',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'go',\n",
       "  'back',\n",
       "  'home',\n",
       "  'since',\n",
       "  'they',\n",
       "  'missed',\n",
       "  'their',\n",
       "  'parents',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'said',\n",
       "  'if',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'could',\n",
       "  'also',\n",
       "  'return',\n",
       "  'to',\n",
       "  'her',\n",
       "  'world',\n",
       "  'they',\n",
       "  'could',\n",
       "  'find',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'home',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
       " ['but',\n",
       "  'the',\n",
       "  'sake',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'he',\n",
       "  'agreed',\n",
       "  ',',\n",
       "  'although',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'sadly',\n",
       "  '.'],\n",
       " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
       " ['the',\n",
       "  'next',\n",
       "  'morning',\n",
       "  'all',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'left',\n",
       "  'with',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'on',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'and',\n",
       "  'his',\n",
       "  'men',\n",
       "  'kidnapped',\n",
       "  'all',\n",
       "  'of',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'tied',\n",
       "  'them',\n",
       "  'and',\n",
       "  'kept',\n",
       "  'them',\n",
       "  'on',\n",
       "  'once',\n",
       "  'of',\n",
       "  'his',\n",
       "  'ships',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'peter',\n",
       "  'found',\n",
       "  'out',\n",
       "  'about',\n",
       "  'it',\n",
       "  'he',\n",
       "  'rushed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'himself',\n",
       "  'from',\n",
       "  'a',\n",
       "  'tress',\n",
       "  'branch',\n",
       "  'and',\n",
       "  'on',\n",
       "  'to',\n",
       "  'the',\n",
       "  'deck',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ship',\n",
       "  'where',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'were',\n",
       "  'tied',\n",
       "  'up',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'bravely',\n",
       "  'and',\n",
       "  'threw',\n",
       "  'over',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'him',\n",
       "  '.'],\n",
       " ['quickly',\n",
       "  'he',\n",
       "  'released',\n",
       "  'everyone',\n",
       "  'from',\n",
       "  'their',\n",
       "  'captor',\n",
       "  '’',\n",
       "  's',\n",
       "  'ties',\n",
       "  '.'],\n",
       " ['wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'michael',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'helped',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  ',',\n",
       "  'where',\n",
       "  'their',\n",
       "  'friends',\n",
       "  'from',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'camp',\n",
       "  'were',\n",
       "  'ready',\n",
       "  'with',\n",
       "  'smaller',\n",
       "  'boats',\n",
       "  'to',\n",
       "  'take',\n",
       "  'them',\n",
       "  'to',\n",
       "  'safety',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'now',\n",
       "  'went',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'let',\n",
       "  'us',\n",
       "  'finished',\n",
       "  'this',\n",
       "  'forever',\n",
       "  'mr.',\n",
       "  'hook',\n",
       "  '”',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'challenged',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'you',\n",
       "  'have',\n",
       "  'caused',\n",
       "  'me',\n",
       "  'enough',\n",
       "  'trouble',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'time',\n",
       "  'that',\n",
       "  'we',\n",
       "  'finished',\n",
       "  'this.',\n",
       "  '”',\n",
       "  'hook',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['with',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'drawn',\n",
       "  ',',\n",
       "  'he',\n",
       "  'raced',\n",
       "  'towards',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  '.'],\n",
       " ['quick',\n",
       "  'on',\n",
       "  'his',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'stepped',\n",
       "  'aside',\n",
       "  'and',\n",
       "  'pushed',\n",
       "  'hook',\n",
       "  'inside',\n",
       "  'the',\n",
       "  'sea',\n",
       "  'where',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'was',\n",
       "  'waiting',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'rejoiced',\n",
       "  'as',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'was',\n",
       "  'out',\n",
       "  'of',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'forever',\n",
       "  '.'],\n",
       " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
       " ['mr.', 'and', 'mrs', '.'],\n",
       " ['darling',\n",
       "  'was',\n",
       "  'so',\n",
       "  'happy',\n",
       "  'to',\n",
       "  'see',\n",
       "  'their',\n",
       "  'children',\n",
       "  'and',\n",
       "  'they',\n",
       "  'agreed',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'even',\n",
       "  'asked',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'to',\n",
       "  'come',\n",
       "  'and',\n",
       "  'live',\n",
       "  'with',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'said',\n",
       "  ',',\n",
       "  'he',\n",
       "  'never',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up',\n",
       "  ',',\n",
       "  'so',\n",
       "  'he',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'will',\n",
       "  'go',\n",
       "  'back',\n",
       "  'to',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  'promised',\n",
       "  'everyone',\n",
       "  'that',\n",
       "  'he',\n",
       "  'will',\n",
       "  'visit',\n",
       "  'again',\n",
       "  'sometime',\n",
       "  '!'],\n",
       " ['and',\n",
       "  'he',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'by',\n",
       "  'his',\n",
       "  'side',\n",
       "  '.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "  \n",
    "sample = open(\"../chap10/data/peter.txt\", \"r\", encoding='UTF8')\n",
    "s = sample.read() \n",
    "  \n",
    "f = s.replace(\"\\n\", \" \")\n",
    "data = [] \n",
    "  \n",
    "for i in sent_tokenize(f):\n",
    "    temp = [] \n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "    data.append(temp) \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' 'wendy' - CBOW :  1.0\n"
     ]
    }
   ],
   "source": [
    "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
    "                              size = 100, window = 5)\n",
    "print(\"Cosine similarity between 'peter' \" +\n",
    "                 \"'wendy' - CBOW : \", \n",
    "      model1.similarity('peter', 'wendy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' 'hook' - CBOW :  0.06274099\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'peter' \" +\n",
    "                 \"'hook' - CBOW : \", \n",
    "      model1.similarity('peter', 'hook')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' wendy' - Skip Gram :  0.31566966\n"
     ]
    }
   ],
   "source": [
    "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, \n",
    "                                             window = 5, sg = 1)\n",
    "print(\"Cosine similarity between 'peter' \" +\n",
    "          \"wendy' - Skip Gram : \", \n",
    "    model2.similarity('peter', 'wendy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' hook' - Skip Gram :  0.5157193\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine similarity between 'peter' \" +\n",
    "            \"hook' - Skip Gram : \", \n",
    "      model2.similarity('peter', 'hook')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText('../chap10/data/peter.txt', size=4, window=3, min_count=1, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14111584\n"
     ]
    }
   ],
   "source": [
    "sim_score = model.wv.similarity('peter', 'wendy')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22405876\n"
     ]
    }
   ],
   "source": [
    "sim_score = model.wv.similarity('peter', 'hook')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wiki.ko.vec 파일 내려받은 후 실습\n",
    "from __future__ import print_function\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_kr = KeyedVectors.load_word2vec_format('../chap10/data/wiki.ko.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 노력함, Similarity: 0.80\n",
      "Word: 노력중, Similarity: 0.75\n",
      "Word: 노력만, Similarity: 0.72\n",
      "Word: 노력과, Similarity: 0.71\n",
      "Word: 노력의, Similarity: 0.69\n",
      "Word: 노력가, Similarity: 0.69\n",
      "Word: 노력이나, Similarity: 0.69\n",
      "Word: 노력없이, Similarity: 0.68\n",
      "Word: 노력맨, Similarity: 0.68\n",
      "Word: 노력보다는, Similarity: 0.68\n"
     ]
    }
   ],
   "source": [
    "find_similar_to = '노력'\n",
    "\n",
    "for similar_word in model_kr.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('초식동물', 0.7804122567176819), ('거대동물', 0.7547270059585571), ('육식동물의', 0.7547166347503662), ('유두동물', 0.7535113096237183), ('반추동물', 0.7470757961273193), ('독동물', 0.7466292381286621), ('육상동물', 0.746031641960144), ('유즐동물', 0.7450904846191406), ('극피동물', 0.7449344992637634), ('복모동물', 0.7424346208572388)]\n"
     ]
    }
   ],
   "source": [
    "similarities = model_kr.wv.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.1.4 횟수/예측기반 임베딩\n",
    "#GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = datapath('../chap10/data/glove.6B.100d.txt') #오류 발생 시 절대 경로로 변경\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('legislation', 0.8072140216827393),\n",
       " ('proposal', 0.7306863069534302),\n",
       " ('senate', 0.7142540812492371),\n",
       " ('bills', 0.7044401168823242),\n",
       " ('measure', 0.6958035230636597),\n",
       " ('passed', 0.6906244158744812),\n",
       " ('amendment', 0.6846879720687866),\n",
       " ('provision', 0.6845567226409912),\n",
       " ('plan', 0.6816462874412537),\n",
       " ('clinton', 0.6663139462471008)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "model.most_similar('bill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peach', 0.688809871673584),\n",
       " ('mango', 0.6838189959526062),\n",
       " ('plum', 0.6684104204177856),\n",
       " ('berry', 0.6590359210968018),\n",
       " ('grove', 0.6581551432609558),\n",
       " ('blossom', 0.6503506302833557),\n",
       " ('raspberry', 0.6477391719818115),\n",
       " ('strawberry', 0.6442098617553711),\n",
       " ('pine', 0.6390928626060486),\n",
       " ('almond', 0.6379213333129883)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('cherry') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('str94', 0.5899436473846436),\n",
       " ('http://www.ecb.int', 0.5723982453346252),\n",
       " ('rw95', 0.5641242265701294),\n",
       " ('js04bb', 0.5608091354370117),\n",
       " ('http://www.opel.com', 0.5586654543876648),\n",
       " ('obloquy', 0.5543686747550964),\n",
       " ('backstrap', 0.5506628155708313),\n",
       " ('disinfects', 0.5451074242591858),\n",
       " ('shepherdesses', 0.5444406270980835),\n",
       " ('hereros', 0.5441645383834839)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative=['cherry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7699\n"
     ]
    }
   ],
   "source": [
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'champagne'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[y1, x2], negative=[x1])\n",
    "    return result[0][0]\n",
    "analogy('australia', 'beer', 'france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'longest'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('tall', 'tallest', 'long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.2 Transformer attention\n",
    "#10.2.1 Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    " \n",
    "import tensorflow as tf\n",
    "import os \n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    " \n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> May I borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf Puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    " \n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    " \n",
    "    return zip(*word_pairs)\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    " \n",
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    " \n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    " \n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    " \n",
    "  return tensor, lang_tokenizer\n",
    " \n",
    "def load_dataset(path, num_examples=None):\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    " \n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    " \n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset('../chap10/data/spa.txt', num_examples)\n",
    " \n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    " \n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    " \n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    " \n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    " \n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))\n",
    " \n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(EDAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    " \n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    " \n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights \n",
    "attention_layer = EDAttention(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = EDAttention(self.dec_units)\n",
    " \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    " \n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    " \n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables)) \n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.5296\n",
      "Epoch 1 Batch 100 Loss 2.1536\n",
      "Epoch 1 Batch 200 Loss 1.8774\n",
      "Epoch 1 Batch 300 Loss 1.7457\n",
      "Epoch 1 Loss 2.0517\n",
      "Epoch 2 Batch 0 Loss 1.5843\n",
      "Epoch 2 Batch 100 Loss 1.6058\n",
      "Epoch 2 Batch 200 Loss 1.3308\n",
      "Epoch 2 Batch 300 Loss 1.2414\n",
      "Epoch 2 Loss 1.3981\n",
      "Epoch 3 Batch 0 Loss 1.0570\n",
      "Epoch 3 Batch 100 Loss 1.0095\n",
      "Epoch 3 Batch 200 Loss 1.0946\n",
      "Epoch 3 Batch 300 Loss 0.9037\n",
      "Epoch 3 Loss 0.9828\n",
      "Epoch 4 Batch 0 Loss 0.7508\n",
      "Epoch 4 Batch 100 Loss 0.6733\n",
      "Epoch 4 Batch 200 Loss 0.7021\n",
      "Epoch 4 Batch 300 Loss 0.5667\n",
      "Epoch 4 Loss 0.6668\n",
      "Epoch 5 Batch 0 Loss 0.5262\n",
      "Epoch 5 Batch 100 Loss 0.4181\n",
      "Epoch 5 Batch 200 Loss 0.5352\n",
      "Epoch 5 Batch 300 Loss 0.4871\n",
      "Epoch 5 Loss 0.4519\n",
      "Epoch 6 Batch 0 Loss 0.3393\n",
      "Epoch 6 Batch 100 Loss 0.3319\n",
      "Epoch 6 Batch 200 Loss 0.3171\n",
      "Epoch 6 Batch 300 Loss 0.2788\n",
      "Epoch 6 Loss 0.3115\n",
      "Epoch 7 Batch 0 Loss 0.2208\n",
      "Epoch 7 Batch 100 Loss 0.2138\n",
      "Epoch 7 Batch 200 Loss 0.2426\n",
      "Epoch 7 Batch 300 Loss 0.2214\n",
      "Epoch 7 Loss 0.2202\n",
      "Epoch 8 Batch 0 Loss 0.1491\n",
      "Epoch 8 Batch 100 Loss 0.1858\n",
      "Epoch 8 Batch 200 Loss 0.1460\n",
      "Epoch 8 Batch 300 Loss 0.1868\n",
      "Epoch 8 Loss 0.1636\n",
      "Epoch 9 Batch 0 Loss 0.1592\n",
      "Epoch 9 Batch 100 Loss 0.1128\n",
      "Epoch 9 Batch 200 Loss 0.1304\n",
      "Epoch 9 Batch 300 Loss 0.1290\n",
      "Epoch 9 Loss 0.1267\n",
      "Epoch 10 Batch 0 Loss 0.0844\n",
      "Epoch 10 Batch 100 Loss 0.0848\n",
      "Epoch 10 Batch 200 Loss 0.0920\n",
      "Epoch 10 Batch 300 Loss 0.1320\n",
      "Epoch 10 Loss 0.1022\n",
      "Time taken for 1 epoch 902.3556807041168 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    " \n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    " \n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    " \n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    " \n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    " \n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    " \n",
    "    sentence = preprocess_sentence(sentence)\n",
    " \n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    " \n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    " \n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_dpi_ratio', { dpi_ratio: fig.ratio });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "    if (this.ratio !== 1) {\n",
       "        fig.send_message('set_dpi_ratio', { dpi_ratio: this.ratio });\n",
       "    }\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    var resizeObserver = new ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    resizeObserver.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch (cursor) {\n",
       "        case 0:\n",
       "            cursor = 'pointer';\n",
       "            break;\n",
       "        case 1:\n",
       "            cursor = 'default';\n",
       "            break;\n",
       "        case 2:\n",
       "            cursor = 'crosshair';\n",
       "            break;\n",
       "        case 3:\n",
       "            cursor = 'move';\n",
       "            break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = 'image/png';\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.which === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.which;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which !== 17) {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    if (event.altKey && event.which !== 18) {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    if (event.shiftKey && event.which !== 16) {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data']);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.one(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager) {\n",
       "        manager = IPython.keyboard_manager;\n",
       "    }\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"720\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    " \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    " \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.2.2 Bert\n",
    "#pip install bert-for-tf2\n",
    "#pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "import bert\n",
    "import pandas as pd\n",
    "movie_reviews = pd.read_csv(\"../chap10/data/IMDB Dataset.csv\")\n",
    "movie_reviews.isnull().values.any()\n",
    "movie_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review' 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(sen):\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "reviews = []\n",
    "sentences = list(movie_reviews['review'])\n",
    "for sen in sentences:\n",
    "    reviews.append(preprocess_text(sen))\n",
    "\n",
    "print(movie_reviews.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = movie_reviews['sentiment']\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines At first it was very odd and pretty funny but as the movie progressed didn find the jokes or oddness funny anymore Its low budget film thats never problem in itself there were some pretty interesting characters but eventually just lost interest imagine this film would appeal to stoner who is currently partaking For something similar but better try Brother from another planet \n"
     ]
    }
   ],
   "source": [
    "print(reviews[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['don', \"'\", 't', 'be', 'so', 'judgment', '##al']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"don't be so judgmental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2123, 1005, 1056, 2022, 2061, 8689, 2389]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"don't be so judgmental\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_reviews(text_reviews):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))\n",
    "tokenized_reviews = [tokenize_reviews(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 21), dtype=int32, numpy=\n",
       " array([[ 3078,  5436,  3078,  3257,  3532,  7613,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2054,  5896,  2054,  2466,  2054,  6752,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 3191,  1996,  2338,  5293,  1996,  3185,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2062, 23873,  3993,  2062, 11259,  2172,  2172,  2062, 14888,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2023,  3185,  2003,  6659,  2021,  2009,  2038,  2070,  2204,\n",
       "          3896,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 1045,  2876,  9278,  2023,  2028,  2130,  2006,  7922, 12635,\n",
       "          2305,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 8235,  1998,  3048,  4616,  2011,  3419,  2457, 27727,  1998,\n",
       "          2848, 16133,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 1045,  3246,  2023,  2177,  1997,  2143, 11153,  2196,  2128,\n",
       "         15908,  2015,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 7918, 14674,  7662,  2003,  6581,  2003,  2023,  2143,  2002,\n",
       "          3084, 17160,  2450,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [11861,  1996, 21442,  6895,  3238,  2515,  2210, 22759,  6198,\n",
       "          1998,  3185,  2087, 12487,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2023,  2003,  2307,  3185,  2205,  2919,  2009,  2003,  2025,\n",
       "          2800,  2006,  2188,  2678,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2017,  2488,  5454,  2703,  2310, 25032,  8913,  8159,  2130,\n",
       "          2065,  2017,  2031,  3427,  2009,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2053,  7615,  5236,  3185,  3772,  2779,  2030,  4788,  9000,\n",
       "          2053,  3168,  2012,  2035, 13558,  2009,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 1045,  2123,  2113,  2339,  2066,  2023,  3185,  2061,  2092,\n",
       "          2021,  2196,  2131,  5458,  1997,  3666,  2009,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2146, 11771,  1038,  8523,  8458,  6633,  3560,  2196,  2031,\n",
       "          2042,  2061,  5580,  2000,  2156,  4566,  6495,  4897,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2074,  2293,  1996,  6970, 13068,  2090,  2048,  2307,  3494,\n",
       "          1997,  2754,  3898,  2310,  3593,  2102,  6287,  5974,     0,\n",
       "             0,     0,     0],\n",
       "        [ 7615,  2023,  3185,  2003,  5263,  2003,  6659,  2200, 17727,\n",
       "          3217,  3676,  3468,  2919,  7613,  3257,  2025,  2298,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
       "          2235,  3077,  2009,  2026,  5440,  2792,  1997,  2235,  3077,\n",
       "             0,     0,     0],\n",
       "        [ 5587,  2023,  2210, 17070,  2000,  2115,  2862,  1997,  6209,\n",
       "         24945,  2009, 26354, 28394,  2102,  6057,  1998,  2203, 27242,\n",
       "             0,     0,     0],\n",
       "        [ 1037,  7244,  3185,  2009,  2003,  2440,  1997,  6699,  1998,\n",
       "          6919,  3772,  2071,  2031,  2938,  2083,  2009,  2117,  2051,\n",
       "             0,     0,     0],\n",
       "        [ 2023,  2003,  1996, 15764,  3185,  2544,  1997,  8429, 24905,\n",
       "         17988,  7659,  2498,  2021,  2045,  2024,  2053, 13842,  5312,\n",
       "             0,     0,     0],\n",
       "        [ 7078, 10392,  3649,  2360,  2876,  2079,  2023,  2104,  9250,\n",
       "          3185,  1996,  3425,  2009, 17210,  3422,  2009,  2085, 10392,\n",
       "             0,     0,     0],\n",
       "        [ 2023,  2003,  2204,  2143,  2023,  2003,  2200,  6057,  2664,\n",
       "          2044,  2023,  2143,  2045,  2020,  2053,  2204,  8471,  3152,\n",
       "             0,     0,     0],\n",
       "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
       "          2235,  3077,  2009,  2026,  5440,  2792,  1997,  2235,  3077,\n",
       "             0,     0,     0],\n",
       "        [ 6283,  2009,  2007,  2035,  2026,  2108,  5409,  3185,  2412,\n",
       "         10597, 21985,  2393,  2033,  2009,  2001,  2008,  2919,  3404,\n",
       "          2033,     0,     0],\n",
       "        [ 1037,  2033,  6491, 11124,  6774,  2143,  2008,  5121,  7906,\n",
       "          2115,  3086,  3841, 13196,  2003, 17160,  1998, 26103,  2000,\n",
       "          3422,     0,     0],\n",
       "        [ 1037,  5790,  1997,  2515,  2025,  4088,  2000,  4671,  2129,\n",
       "         10634,  2139, 24128,  1998, 21660,  2135,  2919,  2023,  3185,\n",
       "          2003,     0,     0],\n",
       "        [ 2005,  5760,  7788,  4393,  8808,  2498,  2064, 12826,  2000,\n",
       "          1996, 11056,  3152,  3811, 16755,  2169,  1998,  2296,  2028,\n",
       "          1997,  2068,     0],\n",
       "        [ 7244,  2092,  2856, 10828,  1997, 10904,  2402,  2472,  3135,\n",
       "          2293,  2466,  2007, 10958,  8428, 10102,  1999,  1996,  4281,\n",
       "          4276,  3773,     0],\n",
       "        [ 2307,  3185,  2926,  1996,  2189,  3802,  2696,  2508,  2012,\n",
       "          2197,  2023,  8847,  6702,  2043,  2017,  2031,  2633,  2179,\n",
       "          2008,  2569,  2619],\n",
       "        [ 2023,  2003,  6659,  3185,  2123,  5949,  2115,  2769,  2006,\n",
       "          2009,  2123,  2130,  3422,  2009,  2005,  2489,  2008,  2035,\n",
       "          2031,  2000,  2360],\n",
       "        [ 2028,  1997,  1996,  4569, 15580,  2102,  5691,  2081,  1999,\n",
       "          3522,  2086,  2204, 23191,  5436,  1998, 11813,  6370,  2191,\n",
       "          2023,  2028,  4438]])>,\n",
       " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 1, 1, 0, 0, 1])>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "reviews_with_len = [[review, y[i], len(review)]\n",
    "                 for i, review in enumerate(tokenized_reviews)]\n",
    "random.shuffle(reviews_with_len)\n",
    "reviews_with_len.sort(key=lambda x: x[2])\n",
    "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))\n",
    "BATCH_SIZE = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
    "next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEXT_MODEL(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 vocabulary_size,\n",
    "                 embedding_dimensions=128,\n",
    "                 cnn_filters=50,\n",
    "                 dnn_units=512,\n",
    "                 model_output_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"text_model\"):\n",
    "        super(TEXT_MODEL, self).__init__(name=name)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocabulary_size,\n",
    "                                          embedding_dimensions)\n",
    "        self.cnn_layer1 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=2,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer2 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=3,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.cnn_layer3 = tf.keras.layers.Conv1D(filters=cnn_filters,\n",
    "                                        kernel_size=4,\n",
    "                                        padding=\"valid\",\n",
    "                                        activation=\"relu\")\n",
    "        self.pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.dense_1 = tf.keras.layers.Dense(units=dnn_units, activation=\"relu\")\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "        if model_output_classes == 2:\n",
    "            self.last_dense = tf.keras.layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = tf.keras.layers.Dense(units=model_output_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        l = self.embedding(inputs)\n",
    "        l_1 = self.cnn_layer1(l) \n",
    "        l_1 = self.pool(l_1) \n",
    "        l_2 = self.cnn_layer2(l) \n",
    "        l_2 = self.pool(l_2)\n",
    "        l_3 = self.cnn_layer3(l)\n",
    "        l_3 = self.pool(l_3)\n",
    "        \n",
    "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) \n",
    "        concatenated = self.dense_1(concatenated)\n",
    "        concatenated = self.dropout(concatenated, training)\n",
    "        model_output = self.last_dense(concatenated)\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200\n",
    "CNN_FILTERS = 100\n",
    "DNN_UNITS = 256\n",
    "OUTPUT_CLASSES = 2\n",
    "DROPOUT_RATE = 0.2\n",
    "NB_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
    "                        embedding_dimensions=EMB_DIM,\n",
    "                        cnn_filters=CNN_FILTERS,\n",
    "                        dnn_units=DNN_UNITS,\n",
    "                        model_output_classes=OUTPUT_CLASSES,\n",
    "                        dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 188s 134ms/step - loss: 0.3018 - accuracy: 0.8676\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 197s 140ms/step - loss: 0.1321 - accuracy: 0.9520\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 188s 134ms/step - loss: 0.0645 - accuracy: 0.9770\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 188s 134ms/step - loss: 0.0374 - accuracy: 0.9868\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 188s 134ms/step - loss: 0.0280 - accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23892c10c88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if OUTPUT_CLASSES == 2:\n",
    "    text_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"accuracy\"])\n",
    "else:\n",
    "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                       optimizer=\"adam\",\n",
    "                       metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "text_model.fit(train_data, epochs=NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 2s 13ms/step - loss: 0.4185 - accuracy: 0.9000\n",
      "[0.41852515935897827, 0.9000400900840759]\n"
     ]
    }
   ],
   "source": [
    "results = text_model.evaluate(test_data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece\n",
    "\n",
    "import pandas as pd\n",
    "import bert\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../chap10/data/train.csv')\n",
    "test_data = pd.read_csv('../chap10/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/2'\n",
    "bert_layer = hub.KerasLayer(url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullTokenizer=bert.bert_tokenization.FullTokenizer\n",
    "\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer=FullTokenizer(vocab_file,do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encoder(texts, tokenizer, max_len=512):    \n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "        \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encoder(train_data, tokenizer, max_len=160)\n",
    "train_labels = train_data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_len=512):\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), \n",
    "                                 dtype=tf.int32, name='positional_ids')\n",
    "    input_segment_ids = tf.keras.layers.Input(shape=(max_len,), \n",
    "                                    dtype=tf.int32, name='segment_ids')\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_len,), \n",
    "                              dtype=tf.int32, name='input_mask')\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, \n",
    "                                                 input_mask, \n",
    "                                                 input_segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(clf_output)\n",
    "    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_segment_ids], \n",
    "                        outputs=output)\n",
    "    model.compile(optimizer= RMSprop(lr=2e-6), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "positional_ids (InputLayer)     [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)      [(None, 1024), (None 335141889   positional_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer_1[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1025        tf_op_layer_strided_slice[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 335,142,914\n",
      "Trainable params: 335,142,913\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(max_len=160)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7689 - accuracy: 0.5000 - val_loss: 0.2230 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4062 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.2560 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.3 한국어 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "text=\"\"\"과일 가게에 사과가 많이 진열되어 있다\n",
    "그녀가 나에게 사과한 후, 우리는 친해졌다\n",
    "애플은 사과 모양을 로고로 사용한다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  1,  2],\n",
       "       [ 0,  0,  0,  1,  2,  3],\n",
       "       [ 0,  0,  1,  2,  3,  4],\n",
       "       [ 0,  1,  2,  3,  4,  5],\n",
       "       [ 1,  2,  3,  4,  5,  6],\n",
       "       [ 0,  0,  0,  0,  7,  8],\n",
       "       [ 0,  0,  0,  7,  8,  9],\n",
       "       [ 0,  0,  7,  8,  9, 10],\n",
       "       [ 0,  7,  8,  9, 10, 11],\n",
       "       [ 7,  8,  9, 10, 11, 12],\n",
       "       [ 0,  0,  0,  0, 13, 14],\n",
       "       [ 0,  0,  0, 13, 14, 15],\n",
       "       [ 0,  0, 13, 14, 15, 16],\n",
       "       [ 0, 13, 14, 15, 16, 17]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = Tokenizer()\n",
    "tok.fit_on_texts([text])\n",
    "\n",
    "vocSize=len(tok.word_index)+1\n",
    "\n",
    "seqs = list()\n",
    "for word in text.split(\"\\n\"):\n",
    "    encoded = tok.texts_to_sequences([word])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        seq = encoded[:i+1]\n",
    "        seqs.append(seq)\n",
    "        \n",
    "maxLen=max(len(i) for i in seqs)\n",
    "\n",
    "seqs=pad_sequences(seqs ,maxlen=maxLen, padding=\"pre\") \n",
    "seqs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = np.array(seqs)\n",
    "x = seqs[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = seqs[:, -1]\n",
    "y = to_categorical(y, num_classes = vocSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8920 - accuracy: 0.0714\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8903 - accuracy: 0.0714\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.8887 - accuracy: 0.1429\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.8870 - accuracy: 0.0714\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8854 - accuracy: 0.0714\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8837 - accuracy: 0.0714\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8821 - accuracy: 0.0714\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8804 - accuracy: 0.0714\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.8786 - accuracy: 0.1429\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8769 - accuracy: 0.1429\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 2.8751 - accuracy: 0.1429\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8732 - accuracy: 0.1429\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8714 - accuracy: 0.1429\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8694 - accuracy: 0.1429\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8674 - accuracy: 0.1429\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.8654 - accuracy: 0.1429\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8632 - accuracy: 0.1429\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.8610 - accuracy: 0.1429\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8587 - accuracy: 0.1429\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8564 - accuracy: 0.1429\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8539 - accuracy: 0.1429\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8513 - accuracy: 0.1429\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8486 - accuracy: 0.1429\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8458 - accuracy: 0.1429\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8428 - accuracy: 0.1429\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8397 - accuracy: 0.1429\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 968us/step - loss: 2.8365 - accuracy: 0.1429\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8331 - accuracy: 0.1429\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8296 - accuracy: 0.1429\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8259 - accuracy: 0.1429\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8219 - accuracy: 0.1429\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8178 - accuracy: 0.1429\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.8135 - accuracy: 0.1429\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.8089 - accuracy: 0.1429\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8041 - accuracy: 0.1429\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7991 - accuracy: 0.1429\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.7938 - accuracy: 0.2143\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7882 - accuracy: 0.2143\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7823 - accuracy: 0.2143\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7761 - accuracy: 0.2143\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7696 - accuracy: 0.2143\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 996us/step - loss: 2.7627 - accuracy: 0.2143\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 978us/step - loss: 2.7555 - accuracy: 0.2143\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.7479 - accuracy: 0.2143\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.7399 - accuracy: 0.2143\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.7314 - accuracy: 0.2143\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7226 - accuracy: 0.21 - 0s 2ms/step - loss: 2.7226 - accuracy: 0.2143\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7134 - accuracy: 0.2143\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.7037 - accuracy: 0.2143\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6936 - accuracy: 0.2143\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6830 - accuracy: 0.2143\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6720 - accuracy: 0.2143\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6606 - accuracy: 0.2143\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6488 - accuracy: 0.2143\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.6365 - accuracy: 0.2143\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6239 - accuracy: 0.2143\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6109 - accuracy: 0.2143\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.5975 - accuracy: 0.2143\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5839 - accuracy: 0.2143\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5699 - accuracy: 0.2143\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 967us/step - loss: 2.5556 - accuracy: 0.1429\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.5410 - accuracy: 0.1429\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5262 - accuracy: 0.1429\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5110 - accuracy: 0.1429\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.4956 - accuracy: 0.1429\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4798 - accuracy: 0.2143\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4637 - accuracy: 0.2143\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.4473 - accuracy: 0.2143\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 2.4304 - accuracy: 0.2143\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4132 - accuracy: 0.2143\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3957 - accuracy: 0.2857\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.3777 - accuracy: 0.3571\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3593 - accuracy: 0.4286\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3405 - accuracy: 0.4286\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.3214 - accuracy: 0.4286\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 983us/step - loss: 2.3018 - accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2818 - accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2615 - accuracy: 0.4286\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2407 - accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.2195 - accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1978 - accuracy: 0.5714\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1758 - accuracy: 0.5714\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1535 - accuracy: 0.5714\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 2.1308 - accuracy: 0.5714\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1078 - accuracy: 0.5714\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0846 - accuracy: 0.5714\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.0612 - accuracy: 0.6429\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0376 - accuracy: 0.6429\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 984us/step - loss: 2.0140 - accuracy: 0.6429\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9902 - accuracy: 0.5714\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9664 - accuracy: 0.5714\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.9426 - accuracy: 0.5714\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.9187 - accuracy: 0.5714\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 942us/step - loss: 1.8949 - accuracy: 0.6429\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 987us/step - loss: 1.8711 - accuracy: 0.6429\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.8473 - accuracy: 0.7143\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8236 - accuracy: 0.7857\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8000 - accuracy: 0.7857\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.7764 - accuracy: 0.7857\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 972us/step - loss: 1.7529 - accuracy: 0.7857\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7295 - accuracy: 0.7857\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7063 - accuracy: 0.7857\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6831 - accuracy: 0.7857\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.6602 - accuracy: 0.7143\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6373 - accuracy: 0.7143\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.6147 - accuracy: 0.7857\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5923 - accuracy: 0.8571\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5701 - accuracy: 0.8571\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5482 - accuracy: 0.8571\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.5266 - accuracy: 0.8571\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5052 - accuracy: 0.8571\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4841 - accuracy: 0.8571\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4633 - accuracy: 0.8571\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4427 - accuracy: 0.8571\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4224 - accuracy: 0.8571\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.4022 - accuracy: 0.8571\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3822 - accuracy: 0.8571\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3624 - accuracy: 0.8571\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3427 - accuracy: 0.8571\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3232 - accuracy: 0.8571\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3037 - accuracy: 0.8571\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2845 - accuracy: 0.8571\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2653 - accuracy: 0.8571\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 986us/step - loss: 1.2463 - accuracy: 0.8571\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.2275 - accuracy: 0.8571\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 954us/step - loss: 1.2089 - accuracy: 0.8571\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1904 - accuracy: 0.8571\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1721 - accuracy: 0.8571\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1540 - accuracy: 0.8571\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1360 - accuracy: 0.8571\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1183 - accuracy: 0.8571\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1008 - accuracy: 0.8571\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0836 - accuracy: 0.8571\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0665 - accuracy: 0.8571\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0497 - accuracy: 0.8571\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0331 - accuracy: 0.8571\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0168 - accuracy: 0.8571\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0006 - accuracy: 0.8571\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.9847 - accuracy: 0.8571\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9691 - accuracy: 0.9286\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9536 - accuracy: 0.9286\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9384 - accuracy: 0.9286\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9235 - accuracy: 0.92 - 0s 1ms/step - loss: 0.9235 - accuracy: 0.9286\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.9089 - accuracy: 0.9286\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.8946 - accuracy: 0.9286\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.8806 - accuracy: 0.9286\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.8670 - accuracy: 0.9286\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8538 - accuracy: 0.9286\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.8409 - accuracy: 0.9286\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 968us/step - loss: 0.8283 - accuracy: 0.9286\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 824us/step - loss: 0.8161 - accuracy: 0.9286\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8041 - accuracy: 0.9286\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7925 - accuracy: 0.9286\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7810 - accuracy: 0.9286\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7698 - accuracy: 0.9286\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7589 - accuracy: 0.9286\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.7481 - accuracy: 0.9286\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.7376 - accuracy: 0.9286\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.7172 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7073 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.6788 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6697 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.6029 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 680us/step - loss: 0.5952 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 951us/step - loss: 0.5802 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5729 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5588 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5384 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4950 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.4670 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4364 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2388cf5ccc0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocSize, 10, input_length= maxLen-1, ))         \n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(vocSize, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics = [\"accuracy\"], optimizer =\"adam\")\n",
    "model.fit(x,y,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentGen(model, tok, word, n):  \n",
    "    sent = \"\"\n",
    "    word2=word\n",
    "    for _ in range(n):  \n",
    "        encoded = tok.texts_to_sequences([word])[0] \n",
    "        encoded = pad_sequences([encoded], maxlen = 7, padding=\"pre\")\n",
    "        res = model.predict_classes(encoded)\n",
    "\n",
    "        for w , i in tok.word_index.items(): \n",
    "            if i == res:  \n",
    "                break \n",
    "        word = word + \" \" + w\n",
    "        sent = sent + \" \" + w\n",
    "    sent = word2 + sent \n",
    "    return sent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-34-a835a6bdf846>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-34-a835a6bdf846>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 5) for input Tensor(\"embedding_1_input:0\", shape=(None, 5), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 5) for input Tensor(\"embedding_1_input:0\", shape=(None, 5), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과일 사과 사과\n"
     ]
    }
   ],
   "source": [
    "print(sentGen(model, tok, \"과일\",2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
